{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf0821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import torchvision.transforms as T\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import gc\n",
    "import gym\n",
    "import gym_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845cd3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32975653\n",
      "Discrete(49)\n",
      "Discrete(32975653)\n",
      "32975653\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('test-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd9baa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "rewards = []\n",
    "count = 5\n",
    "\n",
    "env.reset()\n",
    "while True:\n",
    "  action = env.action_space.sample()\n",
    "  reward = env.step(action)\n",
    "  actions.append(action)\n",
    "  rewards.append(reward)\n",
    "  count -= 1\n",
    "  if count==0:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41fb3a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>chid</th>\n",
       "      <th>txn_cnt</th>\n",
       "      <th>txn_amt</th>\n",
       "      <th>domestic_offline_cnt</th>\n",
       "      <th>domestic_online_cnt</th>\n",
       "      <th>overseas_offline_cnt</th>\n",
       "      <th>overseas_online_cnt</th>\n",
       "      <th>domestic_offline_amt_pct</th>\n",
       "      <th>domestic_online_amt_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>educd</th>\n",
       "      <th>trdtp</th>\n",
       "      <th>naty</th>\n",
       "      <th>poscd</th>\n",
       "      <th>cuorg</th>\n",
       "      <th>slam</th>\n",
       "      <th>gender_code</th>\n",
       "      <th>age</th>\n",
       "      <th>primary_card</th>\n",
       "      <th>shop_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10321418</td>\n",
       "      <td>3</td>\n",
       "      <td>3891.965283</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95982.822967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10414574</td>\n",
       "      <td>2</td>\n",
       "      <td>10616.561549</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>130702.351368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10134567</td>\n",
       "      <td>2</td>\n",
       "      <td>23527.655416</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>112010.611717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10001003</td>\n",
       "      <td>9</td>\n",
       "      <td>17751.558260</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>59701.507360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10267183</td>\n",
       "      <td>1</td>\n",
       "      <td>21701.307598</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dt      chid  txn_cnt       txn_amt  domestic_offline_cnt  \\\n",
       "0   1  10321418        3   3891.965283                     3   \n",
       "1   1  10414574        2  10616.561549                     2   \n",
       "2   1  10134567        2  23527.655416                     0   \n",
       "3   1  10001003        9  17751.558260                     7   \n",
       "4   1  10267183        1  21701.307598                     1   \n",
       "\n",
       "   domestic_online_cnt  overseas_offline_cnt  overseas_online_cnt  \\\n",
       "0                    0                     0                    0   \n",
       "1                    0                     0                    0   \n",
       "2                    2                     0                    0   \n",
       "3                    2                     0                    0   \n",
       "4                    0                     0                    0   \n",
       "\n",
       "   domestic_offline_amt_pct  domestic_online_amt_pct  ...  educd  trdtp  naty  \\\n",
       "0                      1.00                     0.00  ...    4.0    5.0   1.0   \n",
       "1                      1.00                     0.00  ...    2.0   15.0   1.0   \n",
       "2                      0.00                     1.00  ...    3.0   11.0   1.0   \n",
       "3                      0.75                     0.25  ...    3.0   11.0   1.0   \n",
       "4                      1.00                     0.00  ...    6.0   15.0   1.0   \n",
       "\n",
       "   poscd  cuorg           slam  gender_code  age  primary_card  shop_tag  \n",
       "0   99.0   30.0   95982.822967          1.0  4.0             1        45  \n",
       "1    2.0   30.0  130702.351368          1.0  3.0             1        15  \n",
       "2    3.0   30.0  112010.611717          0.0  4.0             1        48  \n",
       "3    2.0   30.0   59701.507360          0.0  3.0             1        48  \n",
       "4   99.0   30.0       0.000000          0.0  6.0             0         2  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.df_xy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d505be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  #replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate\n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "EPSILON = 0.8           # probability of chosing on-policy action\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e220a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1015: RuntimeWarning: overflow encountered in square\n",
      "  temp **= 2\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1021: RuntimeWarning: overflow encountered in square\n",
      "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1021: RuntimeWarning: invalid value encountered in subtract\n",
      "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:80: RuntimeWarning: overflow encountered in square\n",
      "  upper_bound = n_samples * eps * var + (n_samples * mean * eps) ** 2\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(sc.fit_transform(env.df_xy.iloc[:, :-1].values), env.df_xy.iloc[:, -1].values, test_size=0.1, random_state=1)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "Y_train = torch.from_numpy(Y_train).double()\n",
    "\n",
    "train_loader = data_utils.DataLoader(data_utils.TensorDataset(X_train, Y_train), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe7d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(52, 16)\n",
    "        self.fc2 = nn.Linear(16, 18)\n",
    "        self.fc3 = nn.Linear(18, 20)\n",
    "        self.fc4 = nn.Linear(20, 24)\n",
    "        self.fc5 = nn.Linear(24, 49)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.25)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = torch.sigmoid(self.fc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eda73fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "  def __init__(self, action_size, seed):\n",
    "    self.action_size = action_size\n",
    "    self.seed = random.seed(seed)\n",
    "\n",
    "\n",
    "    # Q - Network\n",
    "    self.qnet_local = DQN().double().to(device)\n",
    "    self.qnet_target = DQN().double().to(device)\n",
    "\n",
    "    self.optimizer = optim.Adam(self.qnet_local.parameters(), lr=0.001)\n",
    "\n",
    "    self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "\n",
    "    self.t_step = 0\n",
    "    self.train_loss = []\n",
    "\n",
    "  def step(self, state, action, reward, next_state, done):\n",
    "    self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "\n",
    "    # learn every 4 timesteps\n",
    "    self.t_step = (self.t_step+1)%64\n",
    "    if self.t_step == 0:\n",
    "      experience = self.memory.sample()\n",
    "      #print('Experience sampled from memory : ', experience)\n",
    "      self.learn(experience, GAMMA)\n",
    "\n",
    "\n",
    "  def epsilon_greedy_action(self, state):\n",
    "    state = state.to(device)\n",
    "    self.qnet_local.eval()\n",
    "    with torch.no_grad():\n",
    "      action_values = self.qnet_local(state).max(1)[1]#.view(1, 1)\n",
    "    self.qnet_local.train()\n",
    "\n",
    "    if random.random() < 0.8:\n",
    "      print('Predicted action based on QNetwork : ', action_values)\n",
    "      return action_values.cpu()\n",
    "    else:\n",
    "      random_action = random.choices(np.arange(self.action_size), k=BATCH_SIZE)\n",
    "      print('Chosing  random actions for the batch : ', random_action)\n",
    "      return torch.DoubleTensor(random_action)\n",
    "  \n",
    "  def learn(self, experiences, gamma):\n",
    "    #print('Started learning')\n",
    "    states, actions, rewards, next_states, done = experiences#experiences[0].state, experiences[0].action, experiences[0].reward, experiences[0].next_state, experiences[0].done \n",
    "    criterion = torch.nn.BCELoss()\n",
    "    self.qnet_local.train()\n",
    "    self.qnet_target.eval()\n",
    "\n",
    "    #predicted_targets = self.qnet_local(states)#.gather(1, actions)\n",
    "\n",
    "    #print(next_states.view(1, 1))\n",
    "    with torch.no_grad():\n",
    "      labels_next = self.qnet_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "    \n",
    "    #print('labels_next {}'.format(labels_next))\n",
    "    \n",
    "    labels = 0 + (gamma * labels_next)\n",
    "    predicted_targets = self.qnet_local(states).gather(1, actions.long())\n",
    "\n",
    "    #print(\"Predicted targets : {}, labels : {}\".format(predicted_targets, labels))\n",
    "\n",
    "    loss = criterion(predicted_targets, labels).to(device)\n",
    "    print(\"===========================Training loss ============================\")\n",
    "    print(loss.item())\n",
    "    self.train_loss.append(loss.item())\n",
    "    self.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    self.optimizer.step()\n",
    "\n",
    "    #print('Total training losses : ', self.train_loss)\n",
    "\n",
    "    #perform soft update\n",
    "    self.soft_update(self.qnet_local, self.qnet_target, TAU)\n",
    "  \n",
    "  def soft_update(self, local_model, target_model, tau):\n",
    "    for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "      target_param.data.copy_(tau*local_param.data + (1-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0151486",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "  def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "    self.action_size = action_size\n",
    "    self.memory = deque(maxlen=buffer_size)\n",
    "    self.batch_size = batch_size\n",
    "    self.experiences = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "    self.seed = random.seed(seed)\n",
    "  \n",
    "  def add(self, state, action, reward, next_state, done):\n",
    "    experience = self.experiences(state, action, reward, next_state, done)\n",
    "    self.memory.append(experience)\n",
    "\n",
    "  def sample(self):\n",
    "     experiences = random.sample(self.memory, k=self.batch_size)\n",
    "     #print('Experiences : ', experiences)\n",
    "     states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).double().to(device)\n",
    "     actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).double().to(device)\n",
    "     rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).double().to(device)\n",
    "     next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).double().to(device)\n",
    "     dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None])).double().to(device)\n",
    "     return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    # experiences = random.sample(self.memory, k=BATCH_SIZE)\n",
    "\n",
    "    # batch = self.experiences(*zip(experiences))\n",
    "\n",
    "    # states = torch.cat(batch.state)\n",
    "    # actions = torch.cat(batch.actions)\n",
    "    # rewards = torch.cat(batch.reward)\n",
    "    # next_states = torch.cat(batch.next_state)\n",
    "    # dones = torch.cat(batch.done)\n",
    "    #return random.sample(self.memory, BATCH_SIZE)\n",
    "\n",
    "    \n",
    "  \n",
    "  def __len__(self):\n",
    "      return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ddf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check reward strategy once\n",
    "# add probability to epsilon_greedy\n",
    "import json\n",
    "deep_agent = Agent(action_size=49, seed=0)\n",
    "num_episodes = 1\n",
    "max_t = 1000\n",
    "state = 0\n",
    "env.state_idx = 0\n",
    "\n",
    "true_positive = []\n",
    "true_negative = []\n",
    "\n",
    "false_positive = []\n",
    "false_negative = []\n",
    "\n",
    "TPR = []\n",
    "FPR = []\n",
    "\n",
    "current_state = env.df_xy.iloc[0, :-1].values\n",
    "\n",
    "for i in range(1):  \n",
    "  #print(\"==========================EPOCH {} COMPLETED===================\".format(i))  \n",
    "\n",
    "  print('Current state : ', i)\n",
    "  score = 0\n",
    "  for state_idx, data in enumerate(train_loader, 0):\n",
    "    inputs, labels = data    \n",
    "    action = deep_agent.epsilon_greedy_action(inputs)\n",
    "    for a in action:\n",
    "      #print('action taken : ', action)\n",
    "      next_state, reward, done, info = env.step(a)\n",
    "      next_state = next_state.iloc[:-1].values\n",
    "      #print('Next state dtype ; ', next_state.dtype)\n",
    "      #print('Next state ', next_state)\n",
    "      deep_agent.step(current_state, a, reward, next_state, done)\n",
    "      current_state = next_state\n",
    "      #state = next_state\n",
    "      #score += reward\n",
    "      #roc_info = json.loads(info)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549db9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8b595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632d622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630fd0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f790a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ae5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b40ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23b87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad8021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4573c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def09f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06c54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d3c036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ad980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f357e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7e0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
